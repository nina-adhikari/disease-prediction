{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import auc,accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path=os.getcwd()\n",
    "loader_path=os.path.abspath(\n",
    "    os.path.join(current_path, '..', 'disease_prediction','data',\n",
    "        )\n",
    "    )\n",
    "sys.path.append(loader_path)\n",
    "import datasets as ds\n",
    "df=ds.load_datasets(\n",
    "    subsets=['train', 'test', 'validate'],\n",
    "    directory='../ddx-dataset/'\n",
    ")\n",
    "dp_data=pd.concat(\n",
    "    [df['train'],df['test'],df['validate']],\n",
    "    axis=0, \n",
    "    ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dp_data.drop('PATHOLOGY', axis=1)\n",
    "y=dp_data['PATHOLOGY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder=LabelEncoder()\n",
    "y_encoded=label_encoder.fit_transform(y)\n",
    "pathologies=label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features=X.select_dtypes(include='int64').columns.tolist()\n",
    "categorical_features=X.select_dtypes(include='object').columns.tolist()\n",
    "features_preprocessor=ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',StandardScaler(),numerical_features),\n",
    "        ('cat',OneHotEncoder(handle_unknown='ignore'),categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(\n",
    "    X, y_encoded, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "X_train_train, X_val, y_train_train, y_val=train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.20,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000,random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(algorithm='SAMME',random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False,eval_metric='logloss',random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to train models and evaluate the AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(X_train_train,y_train_train,X_val,y_val):\n",
    "    auc_scores={}\n",
    "    for name,model in models.items():\n",
    "        pipeline=Pipeline(\n",
    "            steps=[\n",
    "                ('pre-processing',features_preprocessor),\n",
    "                ('classifier',model)\n",
    "            ]\n",
    "        )\n",
    "        pipeline.fit(X_train_train,y_train_train)\n",
    "        y_predicted_probability=pipeline.predict_proba(X_val)[:,1]\n",
    "        auc_score=roc_auc_score(y_val,y_predicted_probability)\n",
    "        auc_scores[name]=auc_score\n",
    "        print(f\"{name} AUC Score: {auc_score}\")\n",
    "    return auc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best model for each pathology based on the AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating models for Allergic sinusitis (1 vs all)\n",
      "Logistic Regression AUC Score: 0.9925385501531407\n",
      "Random Forest AUC Score: 0.9919728709757185\n",
      "Gradient Boosting AUC Score: 0.9926949651262742\n",
      "AdaBoost AUC Score: 0.992039527480967\n",
      "Decision Tree AUC Score: 0.9704077694291333\n",
      "XGBoost AUC Score: 0.9922498786517324\n",
      "Best model for Allergic sinusitis: Gradient Boosting with AUC 0.9926949651262742\n",
      "\n",
      "Evaluating models for Anaphylaxis (1 vs all)\n",
      "Logistic Regression AUC Score: 0.9227286087074984\n",
      "Random Forest AUC Score: 0.9145673146123233\n",
      "Gradient Boosting AUC Score: 0.9228146089616964\n",
      "AdaBoost AUC Score: 0.879859648646133\n",
      "Decision Tree AUC Score: 0.8767559214125876\n",
      "XGBoost AUC Score: 0.9217241364636315\n",
      "Best model for Anaphylaxis: Gradient Boosting with AUC 0.9228146089616964\n",
      "\n",
      "Evaluating models for Chagas (1 vs all)\n",
      "Logistic Regression AUC Score: 0.9061335541768581\n",
      "Random Forest AUC Score: 0.885437360696653\n",
      "Gradient Boosting AUC Score: 0.9084517192920405\n",
      "AdaBoost AUC Score: 0.895816918022331\n",
      "Decision Tree AUC Score: 0.8365093819354128\n",
      "XGBoost AUC Score: 0.905759669119381\n",
      "Best model for Chagas: Gradient Boosting with AUC 0.9084517192920405\n",
      "\n",
      "Evaluating models for Ebola (1 vs all)\n",
      "Logistic Regression AUC Score: 0.9243243970767787\n",
      "Random Forest AUC Score: 0.6837962382605286\n",
      "Gradient Boosting AUC Score: 0.9323945161897524\n",
      "AdaBoost AUC Score: 0.9327092847287745\n",
      "Decision Tree AUC Score: 0.6681001537689505\n",
      "XGBoost AUC Score: 0.9184007754073423\n",
      "Best model for Ebola: AdaBoost with AUC 0.9327092847287745\n",
      "\n",
      "Evaluating models for HIV (initial infection) (1 vs all)\n",
      "Logistic Regression AUC Score: 0.8794189932851931\n",
      "Random Forest AUC Score: 0.8705683211093029\n",
      "Gradient Boosting AUC Score: 0.8790901646639234\n",
      "AdaBoost AUC Score: 0.8597007789172283\n",
      "Decision Tree AUC Score: 0.8182430263542733\n",
      "XGBoost AUC Score: 0.8779845088925153\n",
      "Best model for HIV (initial infection): Logistic Regression with AUC 0.8794189932851931\n",
      "\n",
      "Evaluating models for Influenza (1 vs all)\n",
      "Logistic Regression AUC Score: 0.8954653072577329\n",
      "Random Forest AUC Score: 0.8870121948088606\n",
      "Gradient Boosting AUC Score: 0.8960891686764174\n",
      "AdaBoost AUC Score: 0.8791301071519488\n",
      "Decision Tree AUC Score: 0.8355585710583088\n",
      "XGBoost AUC Score: 0.8956598659319324\n",
      "Best model for Influenza: Gradient Boosting with AUC 0.8960891686764174\n",
      "\n",
      "Evaluating models for Localized edema (1 vs all)\n",
      "Logistic Regression AUC Score: 0.9625690735470285\n",
      "Random Forest AUC Score: 0.961694157481223\n",
      "Gradient Boosting AUC Score: 0.9625943251457819\n",
      "AdaBoost AUC Score: 0.9622300172556475\n",
      "Decision Tree AUC Score: 0.925715658029525\n",
      "XGBoost AUC Score: 0.9618559109764669\n",
      "Best model for Localized edema: Gradient Boosting with AUC 0.9625943251457819\n",
      "\n",
      "Evaluating models for SLE (1 vs all)\n",
      "Logistic Regression AUC Score: 0.9304211354499357\n",
      "Random Forest AUC Score: 0.9239056123764835\n",
      "Gradient Boosting AUC Score: 0.9304946822407341\n",
      "AdaBoost AUC Score: 0.930132661508465\n",
      "Decision Tree AUC Score: 0.8747405953557083\n",
      "XGBoost AUC Score: 0.9303153908417481\n",
      "Best model for SLE: Gradient Boosting with AUC 0.9304946822407341\n",
      "\n",
      "Evaluating models for Sarcoidosis (1 vs all)\n",
      "Logistic Regression AUC Score: 0.9519990044561017\n",
      "Random Forest AUC Score: 0.95006723435217\n",
      "Gradient Boosting AUC Score: 0.9520558065948793\n",
      "AdaBoost AUC Score: 0.9522981120520627\n",
      "Decision Tree AUC Score: 0.9117870048758235\n",
      "XGBoost AUC Score: 0.9516365034690241\n",
      "Best model for Sarcoidosis: AdaBoost with AUC 0.9522981120520627\n",
      "\n",
      "Evaluating models for Tuberculosis (1 vs all)\n",
      "Logistic Regression AUC Score: 0.9583394355347663\n",
      "Random Forest AUC Score: 0.9553035462375171\n",
      "Gradient Boosting AUC Score: 0.9587879728626053\n",
      "AdaBoost AUC Score: 0.9587006905000557\n",
      "Decision Tree AUC Score: 0.9092757823811116\n",
      "XGBoost AUC Score: 0.9577890355273415\n",
      "Best model for Tuberculosis: Gradient Boosting with AUC 0.9587879728626053\n",
      "\n",
      "Evaluating models for Whooping cough (1 vs all)\n",
      "Logistic Regression AUC Score: 1.0\n",
      "Random Forest AUC Score: 1.0\n",
      "Gradient Boosting AUC Score: 1.0\n",
      "AdaBoost AUC Score: 1.0\n",
      "Decision Tree AUC Score: 1.0\n",
      "XGBoost AUC Score: 1.0\n",
      "Best model for Whooping cough: Logistic Regression with AUC 1.0\n"
     ]
    }
   ],
   "source": [
    "best_model={}\n",
    "for pathology in pathologies:\n",
    "    print(f\"\\nEvaluating models for {pathology} (1 vs all)\")\n",
    "    pathology_index=label_encoder.transform([pathology])[0]\n",
    "    y_train_binary = (y_train_train==pathology_index).astype(int)\n",
    "    y_val_binary = (y_val == pathology_index).astype(int)\n",
    "    auc_scores=model_selection(X_train_train, y_train_binary, X_val, y_val_binary)\n",
    "    best_model_name=max(auc_scores, key=auc_scores.get)\n",
    "    best_model[pathology]=(best_model_name,auc_scores[best_model_name])\n",
    "    print(f\"Best model for {pathology}: {best_model_name} with AUC {auc_scores[best_model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best models for each pathologies:\n",
      "Allergic sinusitis: Gradient Boosting (AUC: 0.99)\n",
      "Anaphylaxis: Gradient Boosting (AUC: 0.92)\n",
      "Chagas: Gradient Boosting (AUC: 0.91)\n",
      "Ebola: AdaBoost (AUC: 0.93)\n",
      "HIV (initial infection): Logistic Regression (AUC: 0.88)\n",
      "Influenza: Gradient Boosting (AUC: 0.9)\n",
      "Localized edema: Gradient Boosting (AUC: 0.96)\n",
      "SLE: Gradient Boosting (AUC: 0.93)\n",
      "Sarcoidosis: AdaBoost (AUC: 0.95)\n",
      "Tuberculosis: Gradient Boosting (AUC: 0.96)\n",
      "Whooping cough: Logistic Regression (AUC: 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest models for each pathologies:\")\n",
    "for pathology, (model_name, auc_score) in best_model.items():\n",
    "    print(f\"{pathology}: {model_name} (AUC: {round(auc_score,2)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the best models for each pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics={}\n",
    "def predict_with_best_model(model_name,X_train,y_train,X_test):\n",
    "    model=models[model_name]\n",
    "    pipeline=Pipeline(\n",
    "        steps=[\n",
    "            ('pre-processing',features_preprocessor),\n",
    "            ('classifier',model)\n",
    "        ]\n",
    "    )\n",
    "    pipeline.fit(X_train,y_train)\n",
    "    y_predicted=pipeline.predict(X_test)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating best model for Allergic sinusitis on the test set\n",
      "Test Accuracy for Allergic sinusitis with Gradient Boosting: 0.9653359360241799\n",
      "Confusion Matrix: \n",
      "[[54696  1106]\n",
      " [ 1096  6626]]\n",
      "Classification Report: \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "             Other       0.98      0.98      0.98     55802\n",
      "Allergic sinusitis       0.86      0.86      0.86      7722\n",
      "\n",
      "          accuracy                           0.97     63524\n",
      "         macro avg       0.92      0.92      0.92     63524\n",
      "      weighted avg       0.97      0.97      0.97     63524\n",
      "\n",
      "\n",
      "Evaluating best model for Anaphylaxis on the test set\n",
      "Test Accuracy for Anaphylaxis with Gradient Boosting: 0.9136546816951073\n",
      "Confusion Matrix: \n",
      "[[54457   157]\n",
      " [ 5328  3582]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.91      1.00      0.95     54614\n",
      " Anaphylaxis       0.96      0.40      0.57      8910\n",
      "\n",
      "    accuracy                           0.91     63524\n",
      "   macro avg       0.93      0.70      0.76     63524\n",
      "weighted avg       0.92      0.91      0.90     63524\n",
      "\n",
      "\n",
      "Evaluating best model for Chagas on the test set\n",
      "Test Accuracy for Chagas with Gradient Boosting: 0.965603551413639\n",
      "Confusion Matrix: \n",
      "[[60644    11]\n",
      " [ 2174   695]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.97      1.00      0.98     60655\n",
      "      Chagas       0.98      0.24      0.39      2869\n",
      "\n",
      "    accuracy                           0.97     63524\n",
      "   macro avg       0.97      0.62      0.69     63524\n",
      "weighted avg       0.97      0.97      0.96     63524\n",
      "\n",
      "\n",
      "Evaluating best model for Ebola on the test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macpc/Library/CloudStorage/OneDrive-FloridaStateUniversity/OnlineLearning/ErdosInstitute/data_science_bc/disease_prediction/project_env/dp-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/macpc/Library/CloudStorage/OneDrive-FloridaStateUniversity/OnlineLearning/ErdosInstitute/data_science_bc/disease_prediction/project_env/dp-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/macpc/Library/CloudStorage/OneDrive-FloridaStateUniversity/OnlineLearning/ErdosInstitute/data_science_bc/disease_prediction/project_env/dp-env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Ebola with AdaBoost: 0.9964895157735659\n",
      "Confusion Matrix: \n",
      "[[63301     0]\n",
      " [  223     0]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       1.00      1.00      1.00     63301\n",
      "       Ebola       0.00      0.00      0.00       223\n",
      "\n",
      "    accuracy                           1.00     63524\n",
      "   macro avg       0.50      0.50      0.50     63524\n",
      "weighted avg       0.99      1.00      0.99     63524\n",
      "\n",
      "\n",
      "Evaluating best model for HIV (initial infection) on the test set\n",
      "Test Accuracy for HIV (initial infection) with Logistic Regression: 0.8119923178641143\n",
      "Confusion Matrix: \n",
      "[[46887  7418]\n",
      " [ 4525  4694]]\n",
      "Classification Report: \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                  Other       0.91      0.86      0.89     54305\n",
      "HIV (initial infection)       0.39      0.51      0.44      9219\n",
      "\n",
      "               accuracy                           0.81     63524\n",
      "              macro avg       0.65      0.69      0.66     63524\n",
      "           weighted avg       0.84      0.81      0.82     63524\n",
      "\n",
      "\n",
      "Evaluating best model for Influenza on the test set\n",
      "Test Accuracy for Influenza with Gradient Boosting: 0.8892072287639318\n",
      "Confusion Matrix: \n",
      "[[53931  1113]\n",
      " [ 5925  2555]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.90      0.98      0.94     55044\n",
      "   Influenza       0.70      0.30      0.42      8480\n",
      "\n",
      "    accuracy                           0.89     63524\n",
      "   macro avg       0.80      0.64      0.68     63524\n",
      "weighted avg       0.87      0.89      0.87     63524\n",
      "\n",
      "\n",
      "Evaluating best model for Localized edema on the test set\n",
      "Test Accuracy for Localized edema with Gradient Boosting: 0.8733392103771803\n",
      "Confusion Matrix: \n",
      "[[46598  8036]\n",
      " [   10  8880]]\n",
      "Classification Report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Other       1.00      0.85      0.92     54634\n",
      "Localized edema       0.52      1.00      0.69      8890\n",
      "\n",
      "       accuracy                           0.87     63524\n",
      "      macro avg       0.76      0.93      0.80     63524\n",
      "   weighted avg       0.93      0.87      0.89     63524\n",
      "\n",
      "\n",
      "Evaluating best model for SLE on the test set\n",
      "Test Accuracy for SLE with Gradient Boosting: 0.957401926830804\n",
      "Confusion Matrix: \n",
      "[[59745    91]\n",
      " [ 2615  1073]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.96      1.00      0.98     59836\n",
      "         SLE       0.92      0.29      0.44      3688\n",
      "\n",
      "    accuracy                           0.96     63524\n",
      "   macro avg       0.94      0.64      0.71     63524\n",
      "weighted avg       0.96      0.96      0.95     63524\n",
      "\n",
      "\n",
      "Evaluating best model for Sarcoidosis on the test set\n",
      "Test Accuracy for Sarcoidosis with AdaBoost: 0.8871450160569234\n",
      "Confusion Matrix: \n",
      "[[56355   399]\n",
      " [ 6770     0]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.89      0.99      0.94     56754\n",
      " Sarcoidosis       0.00      0.00      0.00      6770\n",
      "\n",
      "    accuracy                           0.89     63524\n",
      "   macro avg       0.45      0.50      0.47     63524\n",
      "weighted avg       0.80      0.89      0.84     63524\n",
      "\n",
      "\n",
      "Evaluating best model for Tuberculosis on the test set\n",
      "Test Accuracy for Tuberculosis with Gradient Boosting: 0.9295227000818588\n",
      "Confusion Matrix: \n",
      "[[55989  2530]\n",
      " [ 1947  3058]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.97      0.96      0.96     58519\n",
      "Tuberculosis       0.55      0.61      0.58      5005\n",
      "\n",
      "    accuracy                           0.93     63524\n",
      "   macro avg       0.76      0.78      0.77     63524\n",
      "weighted avg       0.93      0.93      0.93     63524\n",
      "\n",
      "\n",
      "Evaluating best model for Whooping cough on the test set\n",
      "Test Accuracy for Whooping cough with Logistic Regression: 1.0\n",
      "Confusion Matrix: \n",
      "[[61776     0]\n",
      " [    0  1748]]\n",
      "Classification Report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         Other       1.00      1.00      1.00     61776\n",
      "Whooping cough       1.00      1.00      1.00      1748\n",
      "\n",
      "      accuracy                           1.00     63524\n",
      "     macro avg       1.00      1.00      1.00     63524\n",
      "  weighted avg       1.00      1.00      1.00     63524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pathology in pathologies:\n",
    "    print(f\"\\nEvaluating best model for {pathology} on the test set\")\n",
    "    pathology_index=label_encoder.transform([pathology])[0]\n",
    "    y_test_binary = (y_test == pathology_index).astype(int)\n",
    "\n",
    "    best_model_name,_= best_model[pathology]\n",
    "    y_predicted=predict_with_best_model(best_model_name,X_train,y_train,X_test)\n",
    "    y_predicted_binary=(y_predicted==pathology_index).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_binary, y_predicted_binary)\n",
    "    conf_matrix = confusion_matrix(y_test_binary, y_predicted_binary)\n",
    "    class_report = classification_report(y_test_binary, y_predicted_binary, target_names=['Other',pathology])\n",
    "\n",
    "    test_metrics[pathology]={\n",
    "        'Accuracy': accuracy,\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Classification Report': classification_report\n",
    "    }\n",
    "\n",
    "    print(f\"Test Accuracy for {pathology} with {best_model_name}: {accuracy}\")\n",
    "    print(f\"Confusion Matrix: \\n{conf_matrix}\")\n",
    "    print(f\"Classification Report: \\n{class_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
