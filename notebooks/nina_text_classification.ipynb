{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPnGOWAAyH5ur8w2j8sFuRd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c35ac14150840f881d46502eb50cbfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0501496a2bc2437285d8c0061fa61f39",
              "IPY_MODEL_f4e6ceb352984d07b3a5081a117b2b7b",
              "IPY_MODEL_2dbb36b5a53c407d91c5c67afc8d0004"
            ],
            "layout": "IPY_MODEL_d96dee286b624d9eacc9aa6de32c86c5"
          }
        },
        "0501496a2bc2437285d8c0061fa61f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d406f7a2ff9348e4b878681cdcc82e54",
            "placeholder": "​",
            "style": "IPY_MODEL_7b034153495249ccac2a2500cb4d419c",
            "value": "Map: 100%"
          }
        },
        "f4e6ceb352984d07b3a5081a117b2b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97fa10f2375a4469a0f0fd1cabc7be1d",
            "max": 203008,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bfa9e6ef98549489a0f2f2f0c7fc5b8",
            "value": 203008
          }
        },
        "2dbb36b5a53c407d91c5c67afc8d0004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78015f1f87d04c67bd6d8061740f7357",
            "placeholder": "​",
            "style": "IPY_MODEL_17f09326839f4fc88a983395a93339ea",
            "value": " 203008/203008 [00:20&lt;00:00, 15499.22 examples/s]"
          }
        },
        "d96dee286b624d9eacc9aa6de32c86c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d406f7a2ff9348e4b878681cdcc82e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b034153495249ccac2a2500cb4d419c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97fa10f2375a4469a0f0fd1cabc7be1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bfa9e6ef98549489a0f2f2f0c7fc5b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78015f1f87d04c67bd6d8061740f7357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17f09326839f4fc88a983395a93339ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8173a0ff49a4445920d72fb62f5e480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55b85a3960394827b7f7918e65b2ee53",
              "IPY_MODEL_f7f801159b8444ad9ca36fb0619e2350",
              "IPY_MODEL_5a6de37f2c904700a7036e36810ca271"
            ],
            "layout": "IPY_MODEL_7d73020ac6c74950a7b318645fbb091b"
          }
        },
        "55b85a3960394827b7f7918e65b2ee53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37abe5629fb34385baa049630bb724ac",
            "placeholder": "​",
            "style": "IPY_MODEL_623ff27556304d318db704402ded52b5",
            "value": "Map: 100%"
          }
        },
        "f7f801159b8444ad9ca36fb0619e2350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_253cc35bb64a4987aff527f95a78089d",
            "max": 25399,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6af78d2e4528424493345560432f677b",
            "value": 25399
          }
        },
        "5a6de37f2c904700a7036e36810ca271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7087471c5cbc41f9b2f18d2de0153b11",
            "placeholder": "​",
            "style": "IPY_MODEL_59c40f08de0d48c8996a915dbf654ab1",
            "value": " 25399/25399 [00:03&lt;00:00, 8020.30 examples/s]"
          }
        },
        "7d73020ac6c74950a7b318645fbb091b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37abe5629fb34385baa049630bb724ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "623ff27556304d318db704402ded52b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "253cc35bb64a4987aff527f95a78089d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af78d2e4528424493345560432f677b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7087471c5cbc41f9b2f18d2de0153b11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c40f08de0d48c8996a915dbf654ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05e183ef9c594b2880cc1b360677e139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_716d9c9f2d8e4a62a6d4b5d46fe3a759",
              "IPY_MODEL_473a160d2fcc472ea5ed8d4e95dd0cea",
              "IPY_MODEL_ad3641d1f15c4cdb9a628d36a9efd513"
            ],
            "layout": "IPY_MODEL_26577f6ecd6b4ae399e980a76e866c34"
          }
        },
        "716d9c9f2d8e4a62a6d4b5d46fe3a759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fad467180d9a486bac24e0470be3fcf2",
            "placeholder": "​",
            "style": "IPY_MODEL_4606b6bb45664dd8b7112c3cea6eabfe",
            "value": "Map: 100%"
          }
        },
        "473a160d2fcc472ea5ed8d4e95dd0cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3e142d9c7041869fd90713bc7ad2bd",
            "max": 25689,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e91b0c05572b49bc9122f676e68d44ee",
            "value": 25689
          }
        },
        "ad3641d1f15c4cdb9a628d36a9efd513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ea3c770d5248449fb968546e5af6cf",
            "placeholder": "​",
            "style": "IPY_MODEL_e6be5b02089e4d549a69aaf17fc8f456",
            "value": " 25689/25689 [00:03&lt;00:00, 14443.88 examples/s]"
          }
        },
        "26577f6ecd6b4ae399e980a76e866c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad467180d9a486bac24e0470be3fcf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4606b6bb45664dd8b7112c3cea6eabfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df3e142d9c7041869fd90713bc7ad2bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e91b0c05572b49bc9122f676e68d44ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6ea3c770d5248449fb968546e5af6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6be5b02089e4d549a69aaf17fc8f456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d93d9512208b4405b332c600917169f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d13969242a74b9f9621420d5c8c7033",
              "IPY_MODEL_edaad2bd74f942a58c39cb99300f02b6",
              "IPY_MODEL_f7edb2bbd16f42c0937b8eb115952f63"
            ],
            "layout": "IPY_MODEL_93d90363b5354d93a12b9d72cc554bc4"
          }
        },
        "4d13969242a74b9f9621420d5c8c7033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f830332b5e74549b3ced8576131c49b",
            "placeholder": "​",
            "style": "IPY_MODEL_264554b2ccf0424aa0d014fd9359d683",
            "value": "model.safetensors: 100%"
          }
        },
        "edaad2bd74f942a58c39cb99300f02b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54b0d01e36b3448e8e49af8b1ec910d6",
            "max": 263260784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3860b43c476547b58b1e30ef785efb7a",
            "value": 263260784
          }
        },
        "f7edb2bbd16f42c0937b8eb115952f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab24a26844224de89c04afbc7e971bc4",
            "placeholder": "​",
            "style": "IPY_MODEL_328bb4bab035426f959738cf3366c417",
            "value": " 263M/263M [00:01&lt;00:00, 188MB/s]"
          }
        },
        "93d90363b5354d93a12b9d72cc554bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f830332b5e74549b3ced8576131c49b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "264554b2ccf0424aa0d014fd9359d683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54b0d01e36b3448e8e49af8b1ec910d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3860b43c476547b58b1e30ef785efb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab24a26844224de89c04afbc7e971bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "328bb4bab035426f959738cf3366c417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Adapted from https://github.com/huggingface/transformers/blob/main/examples/tensorflow/text-classification/run_text_classification.py"
      ],
      "metadata": {
        "id": "I233z7YiKOqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ku_-ZUxN9BxW",
        "outputId": "475d2654-e1aa-48b3-cf50-3224035a75c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 evaluate-0.4.2 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2R4puen_t7d",
        "outputId": "27a71f53-7122-4014-890c-f4bdbd88c60d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE = 'drive/MyDrive/Disease-Prediction/ddx-dataset/'"
      ],
      "metadata": {
        "id": "oLH6jhuD_yxI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from packaging.version import parse\n",
        "\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    HfArgumentParser,\n",
        "    PretrainedConfig,\n",
        "    PushToHubCallback,\n",
        "    TFAutoModelForSequenceClassification,\n",
        "    TFTrainingArguments,\n",
        "    create_optimizer,\n",
        "    set_seed,\n",
        ")\n",
        "from transformers.utils import CONFIG_NAME, TF2_WEIGHTS_NAME, send_example_telemetry\n",
        "\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"  # Reduce the amount of console output from TF\n",
        "import tensorflow as tf  # noqa: E402\n",
        "\n",
        "\n",
        "try:\n",
        "    import tf_keras as keras\n",
        "except (ModuleNotFoundError, ImportError):\n",
        "    import keras\n",
        "\n",
        "    if parse(keras.__version__).major > 2:\n",
        "        raise ValueError(\n",
        "            \"Your currently installed version of Keras is Keras 3, but this is not yet supported in \"\n",
        "            \"Transformers. Please install the backwards-compatible tf-keras package with \"\n",
        "            \"`pip install tf-keras`.\"\n",
        "        )"
      ],
      "metadata": {
        "id": "nRsD3CAAa6AL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "5Mov3L-7bVpG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# region Helper classes\n",
        "class SavePretrainedCallback(keras.callbacks.Callback):\n",
        "    # Hugging Face models have a save_pretrained() method that saves both the weights and the necessary\n",
        "    # metadata to allow them to be loaded as a pretrained model in future. This is a simple Keras callback\n",
        "    # that saves the model with this method after each epoch.\n",
        "    def __init__(self, output_dir, **kwargs):\n",
        "        super().__init__()\n",
        "        self.output_dir = output_dir\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.model.save_pretrained(self.output_dir)\n",
        "\n",
        "\n",
        "# endregion"
      ],
      "metadata": {
        "id": "c2vuBNydbX_o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# region Command-line arguments\n",
        "@dataclass\n",
        "class DataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "\n",
        "    Using `HfArgumentParser` we can turn this class\n",
        "    into argparse arguments to be able to specify them on\n",
        "    the command line.\n",
        "    \"\"\"\n",
        "\n",
        "    train_file: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"A csv or a json file containing the training data.\"}\n",
        "    )\n",
        "    validation_file: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n",
        "    )\n",
        "    test_file: Optional[str] = field(default=None, metadata={\"help\": \"A csv or a json file containing the test data.\"})\n",
        "\n",
        "    max_seq_length: int = field(\n",
        "        default=128,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "                \"than this will be truncated, sequences shorter will be padded.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    overwrite_cache: bool = field(\n",
        "        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n",
        "    )\n",
        "    pad_to_max_length: bool = field(\n",
        "        default=False,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"Whether to pad all samples to `max_seq_length`. \"\n",
        "                \"If False, will pad the samples dynamically when batching to the maximum length in the batch. \"\n",
        "                \"Data will always be padded when using TPUs.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    max_train_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
        "                \"value if set.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    max_val_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"For debugging purposes or quicker training, truncate the number of validation examples to this \"\n",
        "                \"value if set.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    max_test_samples: Optional[int] = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"For debugging purposes or quicker training, truncate the number of test examples to this \"\n",
        "                \"value if set.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "\n",
        "    def __post_init__(self):\n",
        "        train_extension = self.train_file.split(\".\")[-1].lower() if self.train_file is not None else None\n",
        "        validation_extension = (\n",
        "            self.validation_file.split(\".\")[-1].lower() if self.validation_file is not None else None\n",
        "        )\n",
        "        test_extension = self.test_file.split(\".\")[-1].lower() if self.test_file is not None else None\n",
        "        extensions = {train_extension, validation_extension, test_extension}\n",
        "        extensions.discard(None)\n",
        "        assert len(extensions) != 0, \"Need to supply at least one of --train_file, --validation_file or --test_file!\"\n",
        "        assert len(extensions) == 1, \"All input files should have the same file extension, either csv or json!\"\n",
        "        assert \"csv\" in extensions or \"json\" in extensions, \"Input files should have either .csv or .json extensions!\"\n",
        "        self.input_file_extension = extensions.pop()\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
        "    \"\"\"\n",
        "\n",
        "    model_name_or_path: str = field(\n",
        "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
        "    )\n",
        "    config_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
        "    )\n",
        "    tokenizer_name: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
        "    )\n",
        "    cache_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
        "    )\n",
        "    model_revision: str = field(\n",
        "        default=\"main\",\n",
        "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name or commit id).\"},\n",
        "    )\n",
        "    token: str = field(\n",
        "        default=None,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"The token to use as HTTP bearer authorization for remote files. If not specified, will use the token \"\n",
        "                \"generated when running `huggingface-cli login` (stored in `~/.huggingface`).\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "    trust_remote_code: bool = field(\n",
        "        default=False,\n",
        "        metadata={\n",
        "            \"help\": (\n",
        "                \"Whether or not to allow for custom models defined on the Hub in their own modeling files. This option \"\n",
        "                \"should only be set to `True` for repositories you trust and in which you have read the code, as it will \"\n",
        "                \"execute code present on the Hub on your local machine.\"\n",
        "            )\n",
        "        },\n",
        "    )\n",
        "\n",
        "\n",
        "# endregion"
      ],
      "metadata": {
        "id": "C23NSkcDbgU2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# region Argument parsing\n",
        "# We now keep distinct sets of args, for a cleaner separation of concerns.\n",
        "\n",
        "training_args = TFTrainingArguments(\n",
        "    output_dir=\"output/\",\n",
        "    overwrite_output_dir=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    do_predict=False,\n",
        "    num_train_epochs=1\n",
        ")\n",
        "model_args = ModelArguments(\n",
        "    model_name_or_path=\"distilbert/distilbert-base-cased\",\n",
        "    tokenizer_name=\"distilbert/distilbert-base-cased\",\n",
        ")\n",
        "data_args = DataTrainingArguments(\n",
        "    train_file= DRIVE+\"text-train.json\",\n",
        "    validation_file= DRIVE+\"text-validate.json\",\n",
        "    test_file= DRIVE+\"text-test.json\",\n",
        "    #max_seq_length=128,\n",
        "    overwrite_cache=True,\n",
        "    max_train_samples=10000,\n",
        "    max_val_samples=1000,\n",
        "    max_test_samples=1000,\n",
        ")\n",
        "\n",
        "# endregion\n",
        "\n",
        "output_dir = training_args.output_dir\n"
      ],
      "metadata": {
        "id": "-x0oEIBsd__W"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# region Checkpoints\n",
        "# Detecting last checkpoint.\n",
        "checkpoint = None\n",
        "if len(os.listdir(training_args.output_dir)) > 0 and not training_args.overwrite_output_dir:\n",
        "    if (output_dir / CONFIG_NAME).is_file() and (output_dir / TF2_WEIGHTS_NAME).is_file():\n",
        "        checkpoint = output_dir\n",
        "        logger.info(\n",
        "            f\"Checkpoint detected, resuming training from checkpoint in {training_args.output_dir}. To avoid this\"\n",
        "            \" behavior, change the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
        "            \"Use --overwrite_output_dir to continue regardless.\"\n",
        "        )\n",
        "\n",
        "# endregion"
      ],
      "metadata": {
        "id": "S-EO_beRfBzL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# region Logging\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    handlers=[logging.StreamHandler(sys.stdout)],\n",
        ")\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "logger.info(f\"Training/evaluation parameters {training_args}\")\n",
        "# endregion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zauatDKifT_E",
        "outputId": "9311671e-cba4-4d06-9a32-458b4f41faa4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Training/evaluation parameters TFTrainingArguments(\n",
            "_n_gpu=-1,\n",
            "accelerator_config=None,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gcp_project=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/runs/May26_15-27-18_6ba13783b926,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=output/,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "poly_power=1.0,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_name=None,\n",
            "tpu_num_cores=None,\n",
            "tpu_zone=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xla=False,\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# region Loading data\n",
        "# For CSV/JSON files, this script will use the 'label' field as the label and the 'sentence1' and optionally\n",
        "# 'sentence2' fields as inputs if they exist. If not, the first two fields not named label are used if at least two\n",
        "# columns are provided. Note that the term 'sentence' can be slightly misleading, as they often contain more than\n",
        "# a single grammatical sentence, when the task requires it.\n",
        "#\n",
        "# If the CSVs/JSONs contain only one non-label column, the script does single sentence classification on this\n",
        "# single column. You can easily tweak this behavior (see below)\n",
        "#\n",
        "# In distributed training, the load_dataset function guarantee that only one local process can concurrently\n",
        "# download the dataset.\n",
        "data_files = {\"train\": data_args.train_file, \"validation\": data_args.validation_file, \"test\": data_args.test_file}\n",
        "data_files = {key: file for key, file in data_files.items() if file is not None}\n",
        "\n",
        "for key in data_files.keys():\n",
        "    logger.info(f\"Loading a local file for {key}: {data_files[key]}\")\n",
        "\n",
        "if data_args.input_file_extension == \"csv\":\n",
        "    # Loading a dataset from local csv files\n",
        "    datasets = load_dataset(\n",
        "        \"csv\",\n",
        "        data_files=data_files,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "        token=model_args.token,\n",
        "    )\n",
        "else:\n",
        "    # Loading a dataset from local json files\n",
        "    datasets = load_dataset(\"json\", data_files=data_files, cache_dir=model_args.cache_dir)\n",
        "# See more about loading any type of standard or custom dataset at\n",
        "# https://huggingface.co/docs/datasets/loading_datasets.\n",
        "# endregion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwY64e4rfZGq",
        "outputId": "bcd3d498-71da-4c6e-be63-3583ffef2d65"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Loading a local file for train: drive/MyDrive/Disease-Prediction/ddx-dataset/text-train.json\n",
            "INFO:__main__:Loading a local file for validation: drive/MyDrive/Disease-Prediction/ddx-dataset/text-validate.json\n",
            "INFO:__main__:Loading a local file for test: drive/MyDrive/Disease-Prediction/ddx-dataset/text-test.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# region Label preprocessing\n",
        "# If you've passed us a training set, we try to infer your labels from it\n",
        "if \"train\" in datasets:\n",
        "    # By default we assume that if your label column looks like a float then you're doing regression,\n",
        "    # and if not then you're doing classification. This is something you may want to change!\n",
        "    is_regression = datasets[\"train\"].features[\"label\"].dtype in [\"float32\", \"float64\"]\n",
        "    if is_regression:\n",
        "        num_labels = 1\n",
        "    else:\n",
        "        # A useful fast method:\n",
        "        # https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.unique\n",
        "        label_list = datasets[\"train\"].unique(\"label\")\n",
        "        label_list.sort()  # Let's sort it for determinism\n",
        "        num_labels = len(label_list)\n",
        "# If you haven't passed a training set, we read label info from the saved model (this happens later)\n",
        "else:\n",
        "    num_labels = None\n",
        "    label_list = None\n",
        "    is_regression = None\n",
        "# endregion"
      ],
      "metadata": {
        "id": "npbgudC_fgrU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# region Load model config and tokenizer\n",
        "if checkpoint is not None:\n",
        "    config_path = training_args.output_dir\n",
        "elif model_args.config_name:\n",
        "    config_path = model_args.config_name\n",
        "else:\n",
        "    config_path = model_args.model_name_or_path\n",
        "if num_labels is not None:\n",
        "    config = AutoConfig.from_pretrained(\n",
        "        config_path,\n",
        "        num_labels=num_labels,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "        revision=model_args.model_revision,\n",
        "        token=model_args.token,\n",
        "        trust_remote_code=model_args.trust_remote_code,\n",
        "    )\n",
        "else:\n",
        "    config = AutoConfig.from_pretrained(\n",
        "        config_path,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "        revision=model_args.model_revision,\n",
        "        token=model_args.token,\n",
        "        trust_remote_code=model_args.trust_remote_code,\n",
        "    )\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
        "    cache_dir=model_args.cache_dir,\n",
        "    revision=model_args.model_revision,\n",
        "    token=model_args.token,\n",
        "    trust_remote_code=model_args.trust_remote_code,\n",
        ")\n",
        "# endregion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9JTJYQifi9D",
        "outputId": "94579c53-cf95-4c2a-d689-e2fd907779f2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# region Dataset preprocessing\n",
        "# Again, we try to have some nice defaults but don't hesitate to tweak to your use case.\n",
        "column_names = {col for cols in datasets.column_names.values() for col in cols}\n",
        "non_label_column_names = [name for name in column_names if name != \"label\"]\n",
        "if \"sentence1\" in non_label_column_names and \"sentence2\" in non_label_column_names:\n",
        "    sentence1_key, sentence2_key = \"sentence1\", \"sentence2\"\n",
        "elif \"sentence1\" in non_label_column_names:\n",
        "    sentence1_key, sentence2_key = \"sentence1\", None\n",
        "else:\n",
        "    if len(non_label_column_names) >= 2:\n",
        "        sentence1_key, sentence2_key = non_label_column_names[:2]\n",
        "    else:\n",
        "        sentence1_key, sentence2_key = non_label_column_names[0], None\n",
        "\n",
        "if data_args.max_seq_length > tokenizer.model_max_length:\n",
        "    logger.warning(\n",
        "        f\"The max_seq_length passed ({data_args.max_seq_length}) is larger than the maximum length for the \"\n",
        "        f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"\n",
        "    )\n",
        "max_seq_length = min(data_args.max_seq_length, tokenizer.model_max_length)\n",
        "\n",
        "# Ensure that our labels match the model's, if it has some pre-specified\n",
        "if \"train\" in datasets:\n",
        "    if not is_regression and config.label2id != PretrainedConfig(num_labels=num_labels).label2id:\n",
        "        label_name_to_id = config.label2id\n",
        "        if sorted(label_name_to_id.keys()) == sorted(label_list):\n",
        "            label_to_id = label_name_to_id  # Use the model's labels\n",
        "        else:\n",
        "            logger.warning(\n",
        "                \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n",
        "                f\"model labels: {sorted(label_name_to_id.keys())}, dataset labels:\"\n",
        "                f\" {sorted(label_list)}.\\nIgnoring the model labels as a result.\",\n",
        "            )\n",
        "            label_to_id = {v: i for i, v in enumerate(label_list)}\n",
        "    elif not is_regression:\n",
        "        label_to_id = {v: i for i, v in enumerate(label_list)}\n",
        "    else:\n",
        "        label_to_id = None\n",
        "    # Now we've established our label2id, let's overwrite the model config with it.\n",
        "    config.label2id = label_to_id\n",
        "    if config.label2id is not None:\n",
        "        config.id2label = {id: label for label, id in label_to_id.items()}\n",
        "    else:\n",
        "        config.id2label = None\n",
        "else:\n",
        "    label_to_id = config.label2id  # Just load the data from the model\n",
        "\n",
        "if \"validation\" in datasets and config.label2id is not None:\n",
        "    validation_label_list = datasets[\"validation\"].unique(\"label\")\n",
        "    for val_label in validation_label_list:\n",
        "        assert val_label in label_to_id, f\"Label {val_label} is in the validation set but not the training set!\"\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Tokenize the texts\n",
        "    args = (\n",
        "        (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
        "    )\n",
        "    result = tokenizer(*args, max_length=max_seq_length, truncation=True)\n",
        "\n",
        "    # Map labels to IDs\n",
        "    if config.label2id is not None and \"label\" in examples:\n",
        "        result[\"label\"] = [(config.label2id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
        "    return result\n",
        "\n",
        "datasets = datasets.map(preprocess_function, batched=True, load_from_cache_file=not data_args.overwrite_cache)\n",
        "\n",
        "# endregion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "6c35ac14150840f881d46502eb50cbfe",
            "0501496a2bc2437285d8c0061fa61f39",
            "f4e6ceb352984d07b3a5081a117b2b7b",
            "2dbb36b5a53c407d91c5c67afc8d0004",
            "d96dee286b624d9eacc9aa6de32c86c5",
            "d406f7a2ff9348e4b878681cdcc82e54",
            "7b034153495249ccac2a2500cb4d419c",
            "97fa10f2375a4469a0f0fd1cabc7be1d",
            "6bfa9e6ef98549489a0f2f2f0c7fc5b8",
            "78015f1f87d04c67bd6d8061740f7357",
            "17f09326839f4fc88a983395a93339ea",
            "f8173a0ff49a4445920d72fb62f5e480",
            "55b85a3960394827b7f7918e65b2ee53",
            "f7f801159b8444ad9ca36fb0619e2350",
            "5a6de37f2c904700a7036e36810ca271",
            "7d73020ac6c74950a7b318645fbb091b",
            "37abe5629fb34385baa049630bb724ac",
            "623ff27556304d318db704402ded52b5",
            "253cc35bb64a4987aff527f95a78089d",
            "6af78d2e4528424493345560432f677b",
            "7087471c5cbc41f9b2f18d2de0153b11",
            "59c40f08de0d48c8996a915dbf654ab1",
            "05e183ef9c594b2880cc1b360677e139",
            "716d9c9f2d8e4a62a6d4b5d46fe3a759",
            "473a160d2fcc472ea5ed8d4e95dd0cea",
            "ad3641d1f15c4cdb9a628d36a9efd513",
            "26577f6ecd6b4ae399e980a76e866c34",
            "fad467180d9a486bac24e0470be3fcf2",
            "4606b6bb45664dd8b7112c3cea6eabfe",
            "df3e142d9c7041869fd90713bc7ad2bd",
            "e91b0c05572b49bc9122f676e68d44ee",
            "f6ea3c770d5248449fb968546e5af6cf",
            "e6be5b02089e4d549a69aaf17fc8f456"
          ]
        },
        "id": "jBHwtTgNgcSo",
        "outputId": "3b4a0fbf-79d9-4dbf-c49b-ea2fe3069581"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/203008 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c35ac14150840f881d46502eb50cbfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25399 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8173a0ff49a4445920d72fb62f5e480"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25689 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05e183ef9c594b2880cc1b360677e139"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pretrained_model(checkpoint, model_args, config, tokenizer):\n",
        "    model_path = checkpoint if checkpoint else model_args.model_name_or_path\n",
        "    return TFAutoModelForSequenceClassification.from_pretrained(\n",
        "        model_path,\n",
        "        config=config,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "        revision=model_args.model_revision,\n",
        "        token=model_args.token,\n",
        "        trust_remote_code=model_args.trust_remote_code,\n",
        "    )"
      ],
      "metadata": {
        "id": "bEI0YoLii9nf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tf_dataset(datasets, data_args, training_args, tokenizer, model):\n",
        "    tf_data = {}\n",
        "    num_replicas = training_args.strategy.num_replicas_in_sync\n",
        "    dataset_options = tf.data.Options()\n",
        "    dataset_options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
        "    num_replicas = training_args.strategy.num_replicas_in_sync\n",
        "\n",
        "    for key in (\"train\", \"validation\", \"test\"):\n",
        "        if key not in datasets or not getattr(training_args, f\"do_{key}\", True):\n",
        "            tf_data[key] = None\n",
        "            continue\n",
        "\n",
        "        assert \"label\" in datasets[key].features if key in (\"train\", \"validation\") else True, f\"Missing labels from {key} data!\"\n",
        "\n",
        "        shuffle = True if key == \"train\" else False\n",
        "        batch_size = (training_args.per_device_train_batch_size if key == \"train\" else training_args.per_device_eval_batch_size) * num_replicas\n",
        "        samples_limit = getattr(data_args, f\"max_{key}_samples\", None)\n",
        "\n",
        "        dataset = datasets[key].select(range(samples_limit)) if samples_limit else datasets[key]\n",
        "\n",
        "        data = model.prepare_tf_dataset(\n",
        "            dataset,\n",
        "            shuffle=shuffle,\n",
        "            batch_size=batch_size,\n",
        "            tokenizer=tokenizer,\n",
        "        )\n",
        "\n",
        "        data = data.with_options(dataset_options)\n",
        "        tf_data[key] = data\n",
        "\n",
        "    return tf_data"
      ],
      "metadata": {
        "id": "UbfZpTX7i_20"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_optimizer_loss_compilation(training_args, model, is_regression):\n",
        "    if training_args.do_train:\n",
        "        num_train_steps = len(tf_data[\"train\"]) * training_args.num_train_epochs\n",
        "        num_warmup_steps = training_args.warmup_steps if training_args.warmup_steps > 0 else int(num_train_steps * training_args.warmup_ratio) if training_args.warmup_ratio > 0 else 0\n",
        "\n",
        "        optimizer, schedule = create_optimizer(\n",
        "            init_lr=training_args.learning_rate,\n",
        "            num_train_steps=num_train_steps,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            adam_beta1=training_args.adam_beta1,\n",
        "            adam_beta2=training_args.adam_beta2,\n",
        "            adam_epsilon=training_args.adam_epsilon,\n",
        "            weight_decay_rate=training_args.weight_decay,\n",
        "            adam_global_clipnorm=training_args.max_grad_norm,\n",
        "        )\n",
        "    else:\n",
        "        optimizer = \"sgd\"  # Just use any default\n",
        "\n",
        "    metrics = [] if is_regression else [\"accuracy\"]\n",
        "    model.compile(optimizer=optimizer, metrics=metrics)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "2LerKT4DjD7i"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_push_to_hub_and_model_card(training_args, model_args, tokenizer, model):\n",
        "    push_to_hub_model_id = training_args.push_to_hub_model_id or f\"{model_args.model_name_or_path.split('/')[-1]}-finetuned-text-classification\"\n",
        "    model_card_kwargs = {\"finetuned_from\": model_args.model_name_or_path, \"tasks\": \"text-classification\"}\n",
        "\n",
        "    callbacks = [\n",
        "        PushToHubCallback(\n",
        "            output_dir=training_args.output_dir,\n",
        "            hub_model_id=push_to_hub_model_id,\n",
        "            hub_token=training_args.push_to_hub_token,\n",
        "            tokenizer=tokenizer,\n",
        "            **model_card_kwargs,\n",
        "        )\n",
        "    ] if training_args.push_to_hub else []\n",
        "\n",
        "    return callbacks"
      ],
      "metadata": {
        "id": "J4Qb_e7ejGj7"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate(tf_data, model, training_args, logger, is_regression):\n",
        "    if tf_data[\"train\"] is not None:\n",
        "        model.fit(\n",
        "            tf_data[\"train\"],\n",
        "            validation_data=tf_data[\"validation\"],\n",
        "            epochs=int(training_args.num_train_epochs),\n",
        "            callbacks=callbacks,\n",
        "        )\n",
        "\n",
        "    if tf_data[\"validation\"] is not None:\n",
        "        logger.info(\"Computing metrics on validation data...\")\n",
        "\n",
        "        if is_regression:\n",
        "            loss = model.evaluate(tf_data[\"validation\"])\n",
        "            logger.info(f\"Eval loss: {loss:.5f}\")\n",
        "        else:\n",
        "            loss, accuracy = model.evaluate(tf_data[\"validation\"])\n",
        "            logger.info(f\"Eval loss: {loss:.5f}, Eval accuracy: {accuracy * 100:.4f}%\")\n",
        "\n",
        "        if training_args.output_dir is not None:\n",
        "            output_eval_file = os.path.join(training_args.output_dir, \"all_results.json\")\n",
        "            eval_dict = {\"eval_loss\": loss}\n",
        "\n",
        "            if not is_regression:\n",
        "                eval_dict[\"eval_accuracy\"] = accuracy\n",
        "\n",
        "            with open(output_eval_file, \"w\") as writer:\n",
        "                writer.write(json.dumps(eval_dict))"
      ],
      "metadata": {
        "id": "60VzMu7YjKt3"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tf_data, model, training_args, logger, config, is_regression):\n",
        "    if tf_data[\"test\"] is not None:\n",
        "        logger.info(\"Doing predictions on test dataset...\")\n",
        "\n",
        "        predictions = model.predict(tf_data[\"test\"])[\"logits\"]\n",
        "        predicted_class = np.squeeze(predictions) if is_regression else np.argmax(predictions, axis=1)\n",
        "        output_test_file = os.path.join(training_args.output_dir, \"test_results.txt\")\n",
        "\n",
        "        with open(output_test_file, \"w\") as writer:\n",
        "            writer.write(\"index\\tprediction\\n\")\n",
        "            for index, item in enumerate(predicted_class):\n",
        "                if is_regression:\n",
        "                    writer.write(f\"{index}\\t{item:3.3f}\\n\")\n",
        "                else:\n",
        "                    item = config.id2label[item]\n",
        "                    writer.write(f\"{index}\\t{item}\\n\")\n",
        "\n",
        "        logger.info(f\"Wrote predictions to {output_test_file}!\")\n",
        "\n",
        "    if training_args.output_dir is not None and not training_args.push_to_hub:\n",
        "        model.save_pretrained(training_args.output_dir)"
      ],
      "metadata": {
        "id": "LzYXGMdJil6J"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained model\n",
        "model = load_pretrained_model(checkpoint, model_args, config, tokenizer)\n",
        "\n",
        "# Convert data to tf.data.Dataset\n",
        "tf_data = convert_to_tf_dataset(datasets, data_args, training_args, tokenizer, model)\n",
        "\n",
        "# Prepare optimizer, loss, and compilation\n",
        "model = prepare_optimizer_loss_compilation(training_args, model, is_regression)\n",
        "\n",
        "# Prepare push to Hub and model card\n",
        "callbacks = prepare_push_to_hub_and_model_card(training_args, model_args, tokenizer, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXFctByQjbNQ",
        "outputId": "38752a87-f9b0-4877-b8f3-979ca94ac104"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and validation\n",
        "train_and_validate(tf_data, model, training_args, logger, is_regression)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYH0o-ApjdmQ",
        "outputId": "f2283897-9976-4a9b-e46b-12c0406d4d6b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250/1250 [==============================] - 245s 171ms/step - loss: 1.0556 - accuracy: 0.5818 - val_loss: 0.9239 - val_accuracy: 0.5780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Computing metrics on validation data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3175/3175 [==============================] - 80s 25ms/step - loss: 0.9239 - accuracy: 0.5780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Eval loss: 0.92392, Eval accuracy: 57.7976%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "predict(tf_data, model, training_args, logger, config, is_regression)"
      ],
      "metadata": {
        "id": "BIwV3r-pjlVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing single sentence text input:"
      ],
      "metadata": {
        "id": "EGr9cq02mviO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from scipy.special import softmax\n",
        "\n",
        "def convert_sentence_to_tf_dataset(sentence, data_args, tokenizer, model):\n",
        "    dataset_options = tf.data.Options()\n",
        "    dataset_options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
        "\n",
        "    dataset = sentence.map(preprocess_function, batched=False, load_from_cache_file=False)\n",
        "\n",
        "    data = model.prepare_tf_dataset(\n",
        "        dataset,\n",
        "        shuffle=shuffle,\n",
        "        batch_size=batch_size,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    data = data.with_options(dataset_options)\n",
        "\n",
        "    return data\n",
        "\n",
        "def predict_sentence(sentence, model):\n",
        "    ds = Dataset.from_list([{'sentence1': sentence}])\n",
        "    asdf = convert_sentence_to_tf_dataset(ds, data_args, tokenizer, model)\n",
        "\n",
        "    predictions = model.predict(sentence)[\"logits\"]\n",
        "    #predicted_class = np.argmax(predictions, axis=1)\n",
        "    #return softmax(predictions)\n",
        "    #return dict(label_list, predictions)"
      ],
      "metadata": {
        "id": "_nXuXvp3mu55"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = predict_sentence(asdf, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOUW14Q_t4kE",
        "outputId": "c49c1a23-d811-4ab2-a844-ebba8a26d2bf"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 160ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSVOINjazwzA",
        "outputId": "ce98dc86-8e26-4329-e242-1ad7f02dd145"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.6699136 ,  1.1461079 , -0.4954011 , -2.167489  ,  0.99298275,\n",
              "         0.94689465,  0.61198187,  0.13981913,  0.12476227, -1.6011727 ,\n",
              "        -1.966471  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "softmax(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIhAawNj2D-z",
        "outputId": "83de6735-f3e2-4d51-e3ee-a75b5292d54e"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01363873, 0.22790639, 0.04414263, 0.00829239, 0.19554879,\n",
              "        0.18674082, 0.13359447, 0.08331647, 0.08207137, 0.01460924,\n",
              "        0.01013866]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMIbWBaV1KJM",
        "outputId": "1a7b4f36-58ac-4b1e-9c12-7d2ef668b77c"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Allergic sinusitis': 0,\n",
              " 'Anaphylaxis': 1,\n",
              " 'Chagas': 2,\n",
              " 'Ebola': 3,\n",
              " 'HIV (initial infection)': 4,\n",
              " 'Influenza': 5,\n",
              " 'Localized edema': 6,\n",
              " 'SLE': 7,\n",
              " 'Sarcoidosis': 8,\n",
              " 'Tuberculosis': 9,\n",
              " 'Whooping cough': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config.id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0EWkL8R1-hv",
        "outputId": "fd10a7d1-0565-4d25-8a1a-cf6a6a68ca07"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Allergic sinusitis',\n",
              " 1: 'Anaphylaxis',\n",
              " 2: 'Chagas',\n",
              " 3: 'Ebola',\n",
              " 4: 'HIV (initial infection)',\n",
              " 5: 'Influenza',\n",
              " 6: 'Localized edema',\n",
              " 7: 'SLE',\n",
              " 8: 'Sarcoidosis',\n",
              " 9: 'Tuberculosis',\n",
              " 10: 'Whooping cough'}"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z62nJdhr1OrA",
        "outputId": "50105ddf-7663-47f1-faa6-7b6dabd2d567"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Allergic sinusitis',\n",
              " 'Anaphylaxis',\n",
              " 'Chagas',\n",
              " 'Ebola',\n",
              " 'HIV (initial infection)',\n",
              " 'Influenza',\n",
              " 'Localized edema',\n",
              " 'SLE',\n",
              " 'Sarcoidosis',\n",
              " 'Tuberculosis',\n",
              " 'Whooping cough']"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading from H5 file"
      ],
      "metadata": {
        "id": "mSZmL8uK2dQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_pretrained_model(checkpoint, model_args, config, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OrpB5qe38AV",
        "outputId": "dc3f46c1-971d-4ef2-d722-71b96183ce14"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"output/saved_model.h5\")"
      ],
      "metadata": {
        "id": "Di7zdtSJ4Wft"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = predict_sentence(asdf, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neGNYlWZ4azT",
        "outputId": "b48440b5-f2a6-4a0a-f321-eada6e8fa1da"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyflRFTi4la7",
        "outputId": "7f7594be-744d-46e0-9836-72ccc6ffc34b"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.9204152 ,  1.2051202 , -0.35945103, -2.2029872 ,  0.7560546 ,\n",
              "         1.0620615 ,  1.2726916 ,  0.05291831,  0.5011906 , -1.3473927 ,\n",
              "        -2.631854  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK0xk8t14m2X",
        "outputId": "02b7b398-33a8-46f2-e59a-739c165147d0"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.6699136 ,  1.1461079 , -0.4954011 , -2.167489  ,  0.99298275,\n",
              "         0.94689465,  0.61198187,  0.13981913,  0.12476227, -1.6011727 ,\n",
              "        -1.966471  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original function"
      ],
      "metadata": {
        "id": "ZrZ4PUgjimeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with training_args.strategy.scope():\n",
        "    # region Load pretrained model\n",
        "    # Set seed before initializing model\n",
        "    set_seed(training_args.seed)\n",
        "    #\n",
        "    # In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n",
        "    # download model & vocab.\n",
        "    if checkpoint is None:\n",
        "        model_path = model_args.model_name_or_path\n",
        "    else:\n",
        "        model_path = checkpoint\n",
        "    model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "        model_path,\n",
        "        config=config,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "        revision=model_args.model_revision,\n",
        "        token=model_args.token,\n",
        "        trust_remote_code=model_args.trust_remote_code,\n",
        "    )\n",
        "    # endregion\n",
        "\n",
        "    # region Convert data to a tf.data.Dataset\n",
        "    dataset_options = tf.data.Options()\n",
        "    dataset_options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
        "    num_replicas = training_args.strategy.num_replicas_in_sync\n",
        "\n",
        "    tf_data = {}\n",
        "    max_samples = {\n",
        "        \"train\": data_args.max_train_samples,\n",
        "        \"validation\": data_args.max_val_samples,\n",
        "        \"test\": data_args.max_test_samples,\n",
        "    }\n",
        "    for key in (\"train\", \"validation\", \"test\"):\n",
        "        if key not in datasets:\n",
        "            tf_data[key] = None\n",
        "            continue\n",
        "        if (\n",
        "            (key == \"train\" and not training_args.do_train)\n",
        "            or (key == \"validation\" and not training_args.do_eval)\n",
        "            or (key == \"test\" and not training_args.do_predict)\n",
        "        ):\n",
        "            tf_data[key] = None\n",
        "            continue\n",
        "        if key in (\"train\", \"validation\"):\n",
        "            assert \"label\" in datasets[key].features, f\"Missing labels from {key} data!\"\n",
        "        if key == \"train\":\n",
        "            shuffle = True\n",
        "            batch_size = training_args.per_device_train_batch_size * num_replicas\n",
        "        else:\n",
        "            shuffle = False\n",
        "            batch_size = training_args.per_device_eval_batch_size * num_replicas\n",
        "        samples_limit = max_samples[key]\n",
        "        dataset = datasets[key]\n",
        "        if samples_limit is not None:\n",
        "            dataset = dataset.select(range(samples_limit))\n",
        "\n",
        "        # model.prepare_tf_dataset() wraps a Hugging Face dataset in a tf.data.Dataset which is ready to use in\n",
        "        # training. This is the recommended way to use a Hugging Face dataset when training with Keras. You can also\n",
        "        # use the lower-level dataset.to_tf_dataset() method, but you will have to specify things like column names\n",
        "        # yourself if you use this method, whereas they are automatically inferred from the model input names when\n",
        "        # using model.prepare_tf_dataset()\n",
        "        # For more info see the docs:\n",
        "        # https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset\n",
        "        # https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.to_tf_dataset\n",
        "\n",
        "        data = model.prepare_tf_dataset(\n",
        "            dataset,\n",
        "            shuffle=shuffle,\n",
        "            batch_size=batch_size,\n",
        "            tokenizer=tokenizer,\n",
        "        )\n",
        "        data = data.with_options(dataset_options)\n",
        "        tf_data[key] = data\n",
        "    # endregion\n",
        "\n",
        "    # region Optimizer, loss and compilation\n",
        "\n",
        "    if training_args.do_train:\n",
        "        num_train_steps = len(tf_data[\"train\"]) * training_args.num_train_epochs\n",
        "        if training_args.warmup_steps > 0:\n",
        "            num_warmup_steps = training_args.warmup_steps\n",
        "        elif training_args.warmup_ratio > 0:\n",
        "            num_warmup_steps = int(num_train_steps * training_args.warmup_ratio)\n",
        "        else:\n",
        "            num_warmup_steps = 0\n",
        "\n",
        "        optimizer, schedule = create_optimizer(\n",
        "            init_lr=training_args.learning_rate,\n",
        "            num_train_steps=num_train_steps,\n",
        "            num_warmup_steps=num_warmup_steps,\n",
        "            adam_beta1=training_args.adam_beta1,\n",
        "            adam_beta2=training_args.adam_beta2,\n",
        "            adam_epsilon=training_args.adam_epsilon,\n",
        "            weight_decay_rate=training_args.weight_decay,\n",
        "            adam_global_clipnorm=training_args.max_grad_norm,\n",
        "        )\n",
        "    else:\n",
        "        optimizer = \"sgd\"  # Just use any default\n",
        "    if is_regression:\n",
        "        metrics = []\n",
        "    else:\n",
        "        metrics = [\"accuracy\"]\n",
        "    # Transformers models compute the right loss for their task by default when labels are passed, and will\n",
        "    # use this for training unless you specify your own loss function in compile().\n",
        "    model.compile(optimizer=optimizer, metrics=metrics)\n",
        "    # endregion\n",
        "\n",
        "    # region Preparing push_to_hub and model card\n",
        "    push_to_hub_model_id = training_args.push_to_hub_model_id\n",
        "    model_name = model_args.model_name_or_path.split(\"/\")[-1]\n",
        "    if not push_to_hub_model_id:\n",
        "        push_to_hub_model_id = f\"{model_name}-finetuned-text-classification\"\n",
        "\n",
        "    model_card_kwargs = {\"finetuned_from\": model_args.model_name_or_path, \"tasks\": \"text-classification\"}\n",
        "\n",
        "    if training_args.push_to_hub:\n",
        "        callbacks = [\n",
        "            PushToHubCallback(\n",
        "                output_dir=training_args.output_dir,\n",
        "                hub_model_id=push_to_hub_model_id,\n",
        "                hub_token=training_args.push_to_hub_token,\n",
        "                tokenizer=tokenizer,\n",
        "                **model_card_kwargs,\n",
        "            )\n",
        "        ]\n",
        "    else:\n",
        "        callbacks = []\n",
        "    # endregion\n",
        "\n",
        "    # region Training and validation\n",
        "    if tf_data[\"train\"] is not None:\n",
        "        model.fit(\n",
        "            tf_data[\"train\"],\n",
        "            validation_data=tf_data[\"validation\"],\n",
        "            epochs=int(training_args.num_train_epochs),\n",
        "            callbacks=callbacks,\n",
        "        )\n",
        "    if tf_data[\"validation\"] is not None:\n",
        "        logger.info(\"Computing metrics on validation data...\")\n",
        "        if is_regression:\n",
        "            loss = model.evaluate(tf_data[\"validation\"])\n",
        "            logger.info(f\"Eval loss: {loss:.5f}\")\n",
        "        else:\n",
        "            loss, accuracy = model.evaluate(tf_data[\"validation\"])\n",
        "            logger.info(f\"Eval loss: {loss:.5f}, Eval accuracy: {accuracy * 100:.4f}%\")\n",
        "        if training_args.output_dir is not None:\n",
        "            output_eval_file = os.path.join(training_args.output_dir, \"all_results.json\")\n",
        "            eval_dict = {\"eval_loss\": loss}\n",
        "            if not is_regression:\n",
        "                eval_dict[\"eval_accuracy\"] = accuracy\n",
        "            with open(output_eval_file, \"w\") as writer:\n",
        "                writer.write(json.dumps(eval_dict))\n",
        "    # endregion\n",
        "\n",
        "    # region Prediction\n",
        "    if tf_data[\"test\"] is not None:\n",
        "        logger.info(\"Doing predictions on test dataset...\")\n",
        "        predictions = model.predict(tf_data[\"test\"])[\"logits\"]\n",
        "        predicted_class = np.squeeze(predictions) if is_regression else np.argmax(predictions, axis=1)\n",
        "        output_test_file = os.path.join(training_args.output_dir, \"test_results.txt\")\n",
        "        with open(output_test_file, \"w\") as writer:\n",
        "            writer.write(\"index\\tprediction\\n\")\n",
        "            for index, item in enumerate(predicted_class):\n",
        "                if is_regression:\n",
        "                    writer.write(f\"{index}\\t{item:3.3f}\\n\")\n",
        "                else:\n",
        "                    item = config.id2label[item]\n",
        "                    writer.write(f\"{index}\\t{item}\\n\")\n",
        "        logger.info(f\"Wrote predictions to {output_test_file}!\")\n",
        "    # endregion\n",
        "\n",
        "    if training_args.output_dir is not None and not training_args.push_to_hub:\n",
        "        # If we're not pushing to hub, at least save a local copy when we're done\n",
        "        model.save_pretrained(training_args.output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "d93d9512208b4405b332c600917169f4",
            "4d13969242a74b9f9621420d5c8c7033",
            "edaad2bd74f942a58c39cb99300f02b6",
            "f7edb2bbd16f42c0937b8eb115952f63",
            "93d90363b5354d93a12b9d72cc554bc4",
            "6f830332b5e74549b3ced8576131c49b",
            "264554b2ccf0424aa0d014fd9359d683",
            "54b0d01e36b3448e8e49af8b1ec910d6",
            "3860b43c476547b58b1e30ef785efb7a",
            "ab24a26844224de89c04afbc7e971bc4",
            "328bb4bab035426f959738cf3366c417"
          ]
        },
        "id": "0SCV2ACRauqv",
        "outputId": "3cee7158-92ec-449f-d92b-ecba53c099cf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/263M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d93d9512208b4405b332c600917169f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7f4e1d9a1cf0> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function infer_framework at 0x7f4e1d9a1cf0> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "1250/1250 [==============================] - 206s 122ms/step - loss: 1.0272 - accuracy: 0.5874 - val_loss: 0.8714 - val_accuracy: 0.5940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Computing metrics on validation data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 5s 38ms/step - loss: 0.8714 - accuracy: 0.5940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:__main__:Eval loss: 0.87139, Eval accuracy: 59.4000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Just running the downloaded file"
      ],
      "metadata": {
        "id": "c6yjTDz7arnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_text_classification.py \\\n",
        "--model_name_or_path distilbert/distilbert-base-cased \\\n",
        "--train_file {DRIVE}\"text-train.json\" \\\n",
        "--validation_file {DRIVE}\"text-validate.json\" \\\n",
        "--output_dir output/ \\\n",
        "--do_train \\\n",
        "--do_eval\n",
        "#--test_file {DRIVE}\"text-test.json\" \\\n",
        "#--do_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4wVdFoR81mq",
        "outputId": "9461ce4d-e5a0-453b-d828-6ccb9d689702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-25 18:36:54.059127: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-25 18:36:54.059175: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-25 18:36:54.060519: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-25 18:36:54.067657: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-25 18:36:55.084747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "05/25/2024 18:36:58 - INFO - __main__ - Training/evaluation parameters TFTrainingArguments(\n",
            "_n_gpu=-1,\n",
            "accelerator_config=None,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_steps=None,\n",
            "eval_strategy=no,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gcp_project=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/runs/May25_18-36-57_e1526b2f02bd,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=output/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "poly_power=1.0,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_name=None,\n",
            "tpu_num_cores=None,\n",
            "tpu_zone=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xla=False,\n",
            ")\n",
            "05/25/2024 18:36:58 - INFO - __main__ - Loading a local file for train: drive/MyDrive/Disease-Prediction/ddx-dataset/text-train.json\n",
            "05/25/2024 18:36:58 - INFO - __main__ - Loading a local file for validation: drive/MyDrive/Disease-Prediction/ddx-dataset/text-validate.json\n",
            "Generating train split: 203008 examples [00:02, 90570.08 examples/s] \n",
            "Generating validation split: 25399 examples [00:01, 24980.26 examples/s]\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "config.json: 100% 465/465 [00:00<00:00, 2.96MB/s]\n",
            "tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 337kB/s]\n",
            "vocab.txt: 100% 213k/213k [00:00<00:00, 920kB/s]\n",
            "tokenizer.json: 100% 436k/436k [00:00<00:00, 30.6MB/s]\n",
            "Map: 100% 203008/203008 [00:21<00:00, 9638.30 examples/s] \n",
            "Map: 100% 25399/25399 [00:02<00:00, 11357.29 examples/s]\n",
            "2024-05-25 18:37:35.303756: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-25 18:37:35.321131: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-25 18:37:35.321340: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-25 18:37:35.322367: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-25 18:37:35.322565: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-25 18:37:35.322751: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-25 18:37:35.551098: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-25 18:37:35.551357: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-25 18:37:35.551494: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2024-05-25 18:37:35.551565: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-25 18:37:35.551704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13949 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "model.safetensors: 100% 263M/263M [00:00<00:00, 359MB/s]\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Epoch 1/3\n",
            "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x78f42df0eb90> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "05/25/2024 18:37:40 - WARNING - tensorflow - AutoGraph could not transform <function infer_framework at 0x78f42df0eb90> and will run it as-is.\n",
            "Cause: for/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "2024-05-25 18:38:19.679076: I external/local_xla/xla/service/service.cc:168] XLA service 0x78f30ffe7ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-05-25 18:38:19.679115: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2024-05-25 18:38:19.697246: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-05-25 18:38:19.743639: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1716662299.840981    1135 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "25376/25376 [==============================] - 2165s 83ms/step - loss: 0.8744 - accuracy: 0.5966 - val_loss: 0.8900 - val_accuracy: 0.5808\n",
            "Epoch 2/3\n",
            "25376/25376 [==============================] - 2100s 83ms/step - loss: 0.8535 - accuracy: 0.6011 - val_loss: 0.8852 - val_accuracy: 0.5808\n",
            "Epoch 3/3\n",
            "25376/25376 [==============================] - 2110s 83ms/step - loss: 0.8467 - accuracy: 0.6037 - val_loss: 0.8816 - val_accuracy: 0.5844\n",
            "05/25/2024 20:23:54 - INFO - __main__ - Computing metrics on validation data...\n",
            "3175/3175 [==============================] - 69s 22ms/step - loss: 0.8816 - accuracy: 0.5844\n",
            "05/25/2024 20:25:04 - INFO - __main__ - Eval loss: 0.88158, Eval accuracy: 58.4354%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a2LFrjAC9x6F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}